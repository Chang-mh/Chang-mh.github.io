[{"content":"Introduction In a previous article, we delved into the intricacies of the FFT algorithm. However, it has an inherent drawback: it operates in the complex number domain. The real and imaginary parts of the complex roots of unity are sine and cosine functions, respectively, involving extensive floating-point calculations. This results in significant computational load, and floating-point arithmetic can also introduce substantial errors.\nSo, can we change the operands to integers? The Number Theoretic Transform (NTT) emerged to answer this call.\nThe Transformation The divide-and-conquer approach used by NTT is entirely identical to that used by FFT. This means NTT can be derived by making simple modifications to the FFT foundation.\nPrimitive Root For a prime number $p$, its primitive root $g$ is an integer such that the sequence $g^1, g^2, \\ldots, g^{p-1} \\mod p$ generates the entire multiplicative group $Z_p^*$ (i.e., all elements in ${1, 2, \\ldots, p-1}$).\nIn other words, the powers of $g$ modulo $p$ are all distinct and cover all integers from $1$ to $p-1$.\nFor example, the prime number $p = 7$.\nCheck $g = 3$: $3^1 \\equiv 3$, $3^2 \\equiv 2$, $3^3 \\equiv 6$, $3^4 \\equiv 4$, $3^5 \\equiv 5$, $3^6 \\equiv 1 \\mod 7$. The sequence is ${3, 2, 6, 4, 5, 1}$, covering all numbers $1-6$. Thus, $3$ is a primitive root modulo $7$. Analogous to the complex roots of unity, we can visualize the values of the primitive root as points on a circle. However, this circle has only a finite number of points, each representing a value in the residue system modulo $p$.\nWe define $\\omega_n \\equiv g^{(p-1)/n} \\mod p$. This $\\omega_n$ defined in this way satisfies the key properties of an $n$-th root of unity:\n$\\omega_n^n \\equiv (g^{(p-1)/n})^n \\equiv g^{p-1} \\equiv 1 \\mod p$ (Fermat\u0026rsquo;s Little Theorem) $\\omega_n^{n/2} \\equiv g^{(p-1)/2} \\equiv -1 \\mod p$ (Because $g^{(p-1)/2}$ is a square root of $1$, which can only be $\\pm 1$ modulo $p$. By the definition of a primitive root, it cannot be $1$, so it must be $-1$.) The sequence $\\omega_n^0, \\omega_n^1, \\ldots, \\omega_n^{n-1}$ consists of distinct elements. Based on these three points, the Cancellation Lemma and the Halving Lemma crucial to FFT also hold:\nCancellation Lemma: $\\omega_{dn}^{dk} = g^{\\frac{p-1}{dn} \\cdot dk} = g^{\\frac{p-1}{n} \\cdot k} = \\omega_n^k$ Halving Lemma: $\\omega_n^{k + n/2} = \\omega_n^k \\cdot \\omega_n^{n/2} = \\omega_n^k \\cdot (-1) = -\\omega_n^k$ Perfect! We now have an element $\\omega_n$ within the integer modulo $p$ domain that perfectly substitutes the complex root of unity.\nWith $\\omega_n$, the implementation of NTT becomes almost identical to FFT. The process remains: Evaluation (NTT) → Pointwise Multiplication → Interpolation (Inverse NTT).\nAssume we have a polynomial $A(x)$ with coefficients modulo $p$ and a degree less than $n$ (where $n$ is a power of $2$, and $n \\mid p-1$).\nForward Transform (NTT) The recursive divide-and-conquer process is exactly the same as FFT:\nSplit the polynomial into two smaller polynomials based on even and odd indices: $A^{[0]}(x)$ and $A^{[1]}(x)$. Recursively compute $\\operatorname{NTT}(A^{[0]})$ and $\\operatorname{NTT}(A^{[1]})$. Combine the results: For $k = 0$ to $n/2 - 1$: $\\operatorname{NTT}(A)[k] = (\\operatorname{NTT}(A^{[0]})[k] + \\omega_n^k \\cdot \\operatorname{NTT}(A^{[1]})[k]) \\mod p$ $\\operatorname{NTT}(A)[k + n/2] = (\\operatorname{NTT}(A^{[0]})[k] - \\omega_n^k \\cdot \\operatorname{NTT}(A^{[1]})[k]) \\mod p$ Note: The addition, multiplication, and modulo operations here are all performed within the integer modulo $p$ domain. There are no floating-point numbers and no precision errors!\nInverse Transform (INTT) The differences between the inverse NTT (INTT) and NTT are only:\nUse $\\omega_n^{-1} \\mod p$ (the modular multiplicative inverse of $\\omega_n$) instead of $\\omega_n$. Multiply the final result by $n^{-1} \\mod p$ (the modular multiplicative inverse of $n$). The formula for INTT is: $\\operatorname{INTT}(A)[k] = \\left( n^{-1} \\cdot \\sum_{j=0}^{n-1} A[j] \\cdot \\omega_n^{-kj} \\right) \\mod p$\nIn practical code, iterative (non-recursive) butterfly operations are usually used to implement NTT/INTT for higher efficiency.\nModulus $p$ NTT has a crucial constraint: the transformation length $n$ must be a divisor of $p-1$. This is because we need $\\omega_n = g^{(p-1)/n}$ to be an integer, which requires that $n$ divides $p-1$.\nThe common practice is to choose primes of special forms where $p-1$ contains a very large power-of-$2$ factor.\nCommon NTT Moduli:\n$p = 469762049 = 7 \\cdot 2^{26} + 1$, $g = 3$\n$p = 998244353 = 7\\cdot17 \\cdot 2^{23} + 1$, $g = 3$ (Note: The original factorization $119 \\cdot 2^{23} + 1$ is also correct as 119=7*17)\n$p = 1004535809 = 479 \\cdot 2^{21} + 1$, $g = 3$\nIf the values in the problem are very large, arbitrary modulus NTT (which combines results from multiple NTTs using different moduli via the Chinese Remainder Theorem) might be necessary.\nSummary Assuming we want to compute $A(x) \\times B(x) \\mod p$, with coefficients in $[0, p-1]$.\nZero-padding: Determine the length $N \\geq \\operatorname{len}(A) + \\operatorname{len}(B) - 1$, ensuring $N$ is a power of $2$ and that $N \\mid (p-1)$. Evaluation (NTT): Compute $\\vec{A\u0026rsquo;} = \\operatorname{NTT}(\\vec{A})$, $\\vec{B\u0026rsquo;} = \\operatorname{NTT}(\\vec{B})$. Pointwise Multiplication: Compute $\\vec{C\u0026rsquo;}[k] = \\vec{A\u0026rsquo;}[k] \\cdot \\vec{B\u0026rsquo;}[k] \\mod p$ for $k=0,1,\\ldots,N-1$. Interpolation (INTT): Compute $\\vec{C} = \\operatorname{INTT}(\\vec{C\u0026rsquo;})$. The result $\\vec{C}$ is the coefficient vector of $A(x) \\times B(x) \\mod p$. The Number Theoretic Transform (NTT) perfectly adapts the ideas of FFT to the integer modulo domain. By substituting the primitive root for the complex root of unity and modular arithmetic for complex arithmetic, it retains the $O(n \\log n)$ computational efficiency while providing absolutely accurate results and faster computation speed. This makes it the algorithm of choice for handling large integer multiplication and polynomial convolution in competitive programming and engineering applications.\n","date":"2025-09-11T00:00:00Z","image":"http://localhost:1313/p/ntt/helena-hertz-wWZzXlDpMog-unsplash_hu_2307260c751d0e0b.jpg","permalink":"http://localhost:1313/en/p/ntt/","title":"NTT Study Notes"},{"content":"Introduction Suppose we have two polynomials:\n\\( A(x) = a_0 + a_1x + a_2x^2 + ... + a_{n-1}x^{n-1} \\)\n\\( B(x) = b_0 + b_1x + b_2x^2 + ... + b_{m-1}x^{m-1} \\)\nWe want to compute their product:\n\\( C(x) = A(x) \\times B(x) = c_0 + c_1x + c_2x^2 + ... + c_{(n+m-2)}x^{(n+m-2)} \\)\nwhere each coefficient \\( c_k = \\sum_{i=0}^{k} a_i b_{k-i} \\).\nIf we compute this directly (convolution), we need approximately \\( n \\times m \\) multiplications and additions. If both \\( n \\) and \\( m \\) are large, this \\( O(n^2) \\) complexity becomes very slow.\nThe Fast Fourier Transform (FFT) provides a way to reduce the complexity to \\( O(n \\log n) \\).\nThe Transformation The standard representation of a polynomial is the Coefficient Representation, which is \\( (a_0, a_1, ..., a_{n-1}) \\) as used above. There is another equivalent representation called the Point-Value Representation.\nIt is well-known that two points uniquely determine a line. What about three points, four points, or even more? It has been proven that a polynomial of degree \\( n-1 \\) can be uniquely determined by its values at \\( n \\) distinct points \\( (x_0, x_1, ..., x_{n-1}) \\), which we can take as given.\nPolynomial multiplication in point-value representation becomes extremely simple: Assume we have polynomials \\( A(x) \\) and \\( B(x) \\).\nTake \\( N \\) points for \\( A(x) \\): \\( (x_k, A(x_k)) \\), \\( k=0,1,...,N-1 \\) Take the same \\( N \\) points for \\( B(x) \\): \\( (x_k, B(x_k)) \\), \\( k=0,1,...,N-1 \\) Note: Here, \\( N \\) must be at least \\(deg(A) + deg(B) + 1 \\) (or more precisely, at least \\(n + m - 1\\)) to uniquely determine the product polynomial \\( C(x) \\). Then the values of the product \\( C(x) = A(x) \\times B(x) \\) at these \\( N \\) points are: \\( (x_k, C(x_k)) = (x_k, A(x_k) \\times B(x_k)) \\), \\( k=0,1,...,N-1 \\) Pointwise multiplication now only takes \\( O(N) \\) time! This is much better than \\( O(N^2) \\).\nThus, the strategy for polynomial multiplication becomes: Coefficient Representation → Point-Value Representation → Pointwise Multiplication → Coefficient Representation\nEvaluation: Convert \\( A(x) \\) and \\( B(x) \\) from coefficient form to point-value form. Pointwise Multiplication: Compute \\( C(x_k) = A(x_k) \\times B(x_k) \\). Interpolation: Convert \\( C(x) \\) from point-value form back to coefficient form. The core question now is: How can we quickly convert between coefficient representation and point-value representation? If we choose any \\( N \\) points arbitrarily, the complexity of the first step (evaluation) and the third step (interpolation) will still be \\( O(N^2) \\) (since computing each \\( A(x_k) \\) takes \\( O(N) \\) time).\nThe ingenuity of the FFT lies in its careful selection of a special set of points and the use of a divide-and-conquer strategy to optimize both the evaluation and interpolation processes to \\( O(N \\log N) \\).\nDFT and Roots of Unity The special set of points chosen by the FFT are the Roots of Unity.\nThe Discrete Fourier Transform (DFT) is the evaluation of a polynomial \\( A(x) \\) at the \\( N \\) N-th roots of unity \\( \\omega_N^0, \\omega_N^1, ..., \\omega_N^{N-1} \\). The resulting values \\( (A(\\omega_N^0), A(\\omega_N^1), ..., A(\\omega_N^{N-1})) \\) are its DFT coefficients.\nThe N-th roots of unity are the \\( N \\) complex solutions to the equation \\( z^N = 1 \\). They can be expressed as: \\( \\omega_N^k = e^{2\\pi i k / N} = \\cos(\\frac{2\\pi k}{N}) + i \\sin(\\frac{2\\pi k}{N}) \\), where \\( k = 0, 1, ..., N-1 \\), and \\( i \\) is the imaginary unit.\nThe roots of unity have several crucial properties that form the basis of the FFT\u0026rsquo;s divide-and-conquer approach:\nCancellation Lemma: \\( \\omega_{2N}^{2k} = \\omega_N^k \\) Halving Lemma: If \\( N \\) is even, then \\( \\omega_N^{k + N/2} = -\\omega_N^k \\) Summation Lemma: This will be used later in the inverse transform. The Magic of Divide-and-Conquer The FFT is an algorithm for computing the DFT quickly. We assume \\( N \\) is a power of 2 (if not, we can pad with zeros to the nearest power of 2).\nWe split the polynomial \\( A(x) \\) into two new polynomials of half the size based on even and odd indices:\n\\( A^{[0]}(x) = a_0 + a_2x + a_4x^2 + ... + a_{N-2}x^{N/2 - 1} \\) (even-indexed coefficients)\n\\( A^{[1]}(x) = a_1 + a_3x + a_5x^2 + ... + a_{N-1}x^{N/2 - 1} \\) (odd-indexed coefficients)\nIt\u0026rsquo;s easy to see that the original polynomial can be expressed as: \\( A(x) = A^{[0]}(x^2) + x A^{[1]}(x^2) \\)\nNow, our problem transforms from \u0026ldquo;evaluate \\( A(x) \\) at \\( N \\) points \\( (\\omega_N^0, \\omega_N^1, ..., \\omega_N^{N-1}) \\)\u0026rdquo; to \u0026ldquo;evaluate \\( A^{[0]}(x) \\) and \\( A^{[1]}(x) \\) at \\( N/2 \\) points \\( ((\\omega_N^0)^2, (\\omega_N^1)^2, ..., (\\omega_N^{N-1})^2) \\)\u0026rdquo;.\nAccording to the Cancellation Lemma: \\( (\\omega_N^k)^2 = \\omega_{N/2}^k \\) Furthermore, \\( (\\omega_N^{k + N/2})^2 = (\\omega_N^k \\omega_N^{N/2})^2 = (\\omega_N^k \\cdot -1)^2 = (\\omega_N^k)^2 = \\omega_{N/2}^k \\)\nThis means that the \\( N \\) squared points we need to evaluate actually consist of only \\( N/2 \\) distinct values: \\( \\omega_{N/2}^0, \\omega_{N/2}^1, ..., \\omega_{N/2}^{N/2 - 1} \\)!\nThus, we can proceed with divide-and-conquer recursion:\nLet \\( y_k^{[0]} = A^{[0]}(\\omega_{N/2}^k) \\) Let \\( y_k^{[1]} = A^{[1]}(\\omega_{N/2}^k) \\) These are DFT problems of size \\( N/2 \\).\nThen, the solution to the original problem \\( A(\\omega_N^k) \\) can be obtained by combining the solutions from the subproblems:\nFor \\( k = 0, 1, ..., N/2 - 1 \\):\n\\( A(\\omega_N^k) = A^{[0]}(\\omega_{N/2}^k) + \\omega_N^k \\cdot A^{[1]}(\\omega_{N/2}^k) = y_k^{[0]} + \\omega_N^k y_k^{[1]} \\)\nFor \\( k = N/2, ..., N-1 \\) (let \\( k’ = k - N/2 \\)):\n\\( \\omega_N^{k} = \\omega_N^{k’ + N/2} = -\\omega_N^{k’} \\) \\( A(\\omega_N^{k}) = A(\\omega_N^{k’ + N/2}) = A^{[0]}(\\omega_{N/2}^{k’}) + \\omega_N^{k’ + N/2} \\cdot A^{[1]}(\\omega_{N/2}^{k’}) = y_{k’}^{[0]} - \\omega_N^{k’} y_{k’}^{[1]} \\)\nThis process is the core of the FFT!\nComplexity Analysis:\nEach recursion level: We break a problem of size \\( N \\) into 2 problems of size \\( N/2 \\), and perform an \\( O(N) \\) merge operation (multiplying by \\( \\omega_N^k \\) and adding). The height of the recursion tree is \\( \\log_2 N \\). Total complexity: \\( T(N) = 2T(N/2) + O(N) = O(N \\log N) \\). IDFT Now we have the point-value representation of \\( C(x) \\): \\( ((\\omega_N^0, C(\\omega_N^0)), (\\omega_N^1, C(\\omega_N^1)), ..., (\\omega_N^{N-1}, C(\\omega_N^{N-1}))) \\). How do we convert it back to coefficients \\( (c_0, c_1, ..., c_{N-1}) \\)? This process is called the Inverse Discrete Fourier Transform (IDFT).\nRemarkably, the process for IDFT is almost identical to that of DFT. The matrix form of the DFT is:\n$$ \\begin{bmatrix} y_0 \\\\ y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_{N-1} \\end{bmatrix} = \\begin{bmatrix} 1 \u0026 1 \u0026 1 \u0026 \\cdots \u0026 1 \\\\ 1 \u0026 \\omega_N \u0026 \\omega_N^2 \u0026 \\cdots \u0026 \\omega_N^{N-1} \\\\ 1 \u0026 \\omega_N^2 \u0026 \\omega_N^4 \u0026 \\cdots \u0026 \\omega_N^{2(N-1)} \\\\ \\vdots \u0026 \\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots \\\\ 1 \u0026 \\omega_N^{N-1} \u0026 \\omega_N^{2(N-1)} \u0026 \\cdots \u0026 \\omega_N^{(N-1)(N-1)} \\end{bmatrix} \\begin{bmatrix} a_0 \\\\ a_1 \\\\ a_2 \\\\ \\vdots \\\\ a_{N-1} \\end{bmatrix} $$ This Vandermonde matrix \\( V \\) is almost invertible. Its inverse matrix \\( V^{-1} \\) is very similar to \\( V \\), except that each element \\( \\omega_N^k \\) is replaced by \\( \\omega_N^{-k} \\), and the entire matrix is multiplied by a factor of \\( 1/N \\).\nThis means that the process to compute the IDFT is:\nTake the point-value vector \\( \\vec{y} \\) as input. Replace all roots of unity \\( \\omega_N^k \\) with their complex conjugates \\( \\omega_N^{-k} \\). Perform the exact same algorithm as the FFT! Finally, divide the result by \\( N \\). Thus, the complexity of IFFT is also \\( O(N \\log N) \\).\nSummary Suppose we want to compute \\( A(x) \\times B(x) \\), with degree bounds \\( n \\) and \\( m \\) respectively.\nZero-padding:\nDetermine the degree bound \\( N \\geq n + m - 1 \\), and ensure \\( N \\) is a power of 2. Pad the coefficient vectors of \\( A(x) \\) and \\( B(x) \\) to length \\( N \\) with zeros. Evaluation (FFT):\nPerform FFT on the zero-padded coefficient vector of \\( A(x) \\) to obtain its point-value representation \\( \\vec{A} = (A(\\omega_N^0), A(\\omega_N^1), ..., A(\\omega_N^{N-1})) \\). Perform FFT on the zero-padded coefficient vector of \\( B(x) \\) to obtain its point-value representation \\( \\vec{B} = (B(\\omega_N^0), B(\\omega_N^1), ..., B(\\omega_N^{N-1})) \\). Pointwise Multiplication:\nCompute \\( \\vec{C} = \\vec{A} \\circ \\vec{B} \\), i.e., \\( C(\\omega_N^k) = A(\\omega_N^k) \\times B(\\omega_N^k) \\) for \\( k=0,1,...,N-1 \\). Interpolation (IFFT):\nPerform the inverse FFT on the point-value vector \\( \\vec{C} \\) (i.e., take the conjugate roots of unity, perform FFT, and then divide by N). The result is the coefficient vector \\( (c_0, c_1, ..., c_{N-1}) \\) of the product polynomial \\( C(x) \\). The final complexity is \\( O(N \\log N) \\), which is far superior to the direct \\( O(N^2) \\) approach.\nThis is why the FFT is a cornerstone algorithm in numerous fields such as signal processing, image processing, and numerical computation. Through clever mathematical transformation and a divide-and-conquer strategy, it dramatically accelerates convolution (polynomial multiplication) operations.\n","date":"2025-09-09T00:00:00Z","image":"http://localhost:1313/p/fft/pexels-lum3n-44775-167682_hu_b54557df4f714bdb.jpg","permalink":"http://localhost:1313/en/p/fft/","title":"FFT Study Notes"}]